import os
import pandas as pd
from openpyxl import load_workbook, Workbook
from openpyxl.utils.dataframe import dataframe_to_rows
from snowflake_connection import get_snowflake_connection
from null_validation import run_null_validation
from distinct_validation import run_distinct_validation
from duplicate_check import run_duplicate_check
from pk_validation import run_primary_key_validation
from run_skew_and_outlier_validation import get_column_types, get_skew_data_with_query, get_outlier_data_with_query
from date_range_validation import run_date_range_validation
from common.logger import logger
import json

def read_table_info_from_excel(file_path):
    df = pd.read_excel(file_path)
    logger.info(f"Loaded table list from Excel: {file_path}")
    return df

def write_df_to_sheet(wb, sheet_name, df):
    logger.info(f"Writing to sheet: {sheet_name} with {len(df)} rows")
    if sheet_name in wb.sheetnames:
        del wb[sheet_name]
    ws = wb.create_sheet(title=sheet_name)
    for row in dataframe_to_rows(df, index=False, header=True):
        if any(row):
            ws.append(row)

def run_validation(excel_path, config_path):
    output_dir = "C:\\TI\\Clms"
    os.makedirs(output_dir, exist_ok=True)

    with open(config_path, 'r') as f:
        config = json.load(f)

    enable_skew_outlier = config.get("enable_skew_outlier", False)
    logger.info(f"Loaded config from: {config_path}")

    table_info_df = read_table_info_from_excel(excel_path)
    validation_status = []

    conn, database, schema, table_name, schema1, table_name1 = get_snowflake_connection(config_path)
    logger.info("Established Snowflake connection")

    try:
        for _, row in table_info_df.iterrows():
            database = str(row["Database"]).strip()
            schema = str(row["Schema"]).strip()
            table = str(row["Table"]).strip()

            logger.info(f"Running validations for table: {database}.{schema}.{table}")

            try:
                null_df = run_null_validation(conn, database, schema, table, schema1, table_name1)
                distinct_df = run_distinct_validation(conn, database, schema, table, schema1, table_name1)
                dup_summary_df, dup_sample_df = run_duplicate_check(conn, database, schema, table, schema1, table_name1)
                pk_df = run_primary_key_validation(conn, database, schema, table, schema1, table_name1)
                date_df = run_date_range_validation(conn, database, schema, table)

                output_file = os.path.join(output_dir, f"{table}.xlsx")

                if os.path.exists(output_file):
                    wb = load_workbook(output_file)
                    logger.info(f"Updating existing workbook: {output_file}")
                else:
                    wb = Workbook()
                    wb.remove(wb.active)
                    logger.info(f"Creating new workbook: {output_file}")

                write_df_to_sheet(wb, "null", null_df)
                write_df_to_sheet(wb, "distinct", distinct_df)
                write_df_to_sheet(wb, "duplicate_check_summary", dup_summary_df)
                if not dup_sample_df.empty:
                    write_df_to_sheet(wb, "duplicate_rows_sample", dup_sample_df)
                write_df_to_sheet(wb, "pk_check", pk_df)
                write_df_to_sheet(wb, "date_range_check", date_df)

                if enable_skew_outlier:
                    cat_cols, num_cols = get_column_types(conn, database, schema, table)
                    skew_df = get_skew_data_with_query(conn, database, schema, table, cat_cols)
                    outlier_df = get_outlier_data_with_query(conn, database, schema, table, num_cols)
                    write_df_to_sheet(wb, "skew_check", skew_df)
                    write_df_to_sheet(wb, "outlier_check", outlier_df)

                wb.save(output_file)
                logger.info(f" Excel saved: {output_file}")

                validation_status.append({
                    "Database": database,
                    "Schema": schema,
                    "Table": table,
                    "Status": "Success",
                    "Error": ""
                })

            except Exception as e:
                logger.error(f" Error processing table {table}: {e}")
                validation_status.append({
                    "Database": database,
                    "Schema": schema,
                    "Table": table,
                    "Status": "Failed",
                    "Error": str(e)
                })

    finally:
        conn.close()
        logger.info(" Snowflake connection closed.")

    status_df = pd.DataFrame(validation_status)
    status_file = os.path.join(output_dir, "validation_status_summary.xlsx")
    status_df.to_excel(status_file, index=False)
    logger.info(f" Validation status written to: {status_file}")
